{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# <span style=\"color:#be2d24\">B31YS Integrated Robotics Project Deadline: Monday 12th of December 2022</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Scenario:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a natural or man-made disaster, the first task for the responders is to find and rescue survivors in the collapsed buildings. Even though technologies such as microphone arrays or search cameras help the responders, it is still a dangerous task: the stricken building might collapse completely and bury the rescue team in case of an aftershock. Search and Rescue robots can help to reduce this risk during these Urban Search and Rescue (USAR) missions. The idea is to send these robots into the rubble pile, and let them search for victims using their sensors such as cameras or heat sensors and report to the rescuers once they have found a person.\n",
    "\n",
    "(**This scenario was taken from RoboCup 2014**) \n",
    "\n",
    "*Pellenz J., Jacoff A., Kimura T., Mihankhah E., Sheh R., Suthakorn J. (2015) RoboCup Rescue Robot League. In: Bianchi R., Akin H., Ramamoorthy S., Sugiura K. (eds) RoboCup 2014: Robot World Cup XVIII. RoboCup 2014. Lecture Notes in Computer Science, vol 8992. Springer, Cham. https://doi.org/10.1007/978-3-319-18615-3_55*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Your Mission:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Prime Contractor leading the robotic search is Sellafield Rescue Services\n",
    "Ltd (SRS). They have ground mobile robots which are largely tele-operated, unable to operate\n",
    "autonomously to search and locate the bodies. They have issued an ITT (invitation to tender)\n",
    "to local companies to provide the ROS based smart software that will enable a mobile robot\n",
    "to find and locate the victims. The ROSBOTS have been chosen by the Prime as test-beds to\n",
    "prototype search and identify methods that can then be transferred to field robotic systems\n",
    "capable of operating on site.\n",
    "\n",
    "The ITT specifically mentions a Capability Demonstration to locate individuals against the\n",
    "clock to help differentiate the offerings. You work for one of the chosen bidders. Your task is\n",
    "to programme the ROSBOT to run at the Capability Demonstration event performing search\n",
    "and identify in an unknown environment.\n",
    "\n",
    "\n",
    "Requirements: SRS brief to tenderers is as follows. The chosen software must:\n",
    "\n",
    "1. Autonomously move the mobile robot in the environment with no initial map, avoiding obstacles, able to dead reckon with or without visual cues (hint: consider calibration methods).\n",
    "\n",
    "2. Build and store a map of the environment and navigate within it (e.g. SLAM).\n",
    "\n",
    "3. Locate up to 6 individuals in the environment and as many signs as possible, which would allow the rescue team to plan a safe route to enter and recover the missing workers, and report their position in the map.\n",
    "\n",
    "The successful tenderer will perform this task in the least time and with the best accuracy of\n",
    "position and reporting of individuals, with penalties for colliding with objects or going outside\n",
    "the area bounding box Capability Demonstrations will be scheduled in stages to assess the\n",
    "progress of each individual tenderer. An environment will be specially arranged for the task.\n",
    "You should be able to prepare in-situ before each milestone. A head to head competition\n",
    "between the five vendors is planned.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*Scenario Views: Real Environment (academic year 2019-2020)*\n",
    "<img src=./images/Picture1.jpg />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Technical Description:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project will be conducted and marked in simulation. However, we intend to migrate to real robots for extra bonus points. Each group will use a robot equipped with a RGBD sensor (that means you have a camera but also potentially 3D point clouds) and a laser scan range finder (2D). You can make use of each sensor in any way you want. We will also provide you with a test environment in Gazebo including the signs to be detected. The final testing will be individual. Examples of scenarios were shown in pictures in this document:\n",
    "\n",
    "\n",
    "The tasks corresponding to each milestone are as follows:\n",
    "\n",
    "1. Obstacle Avoidance & Path Planning (20% of overall mark): Your robot will be required to navigate the environment without colliding with objects in its way whilst reaching a designated target position in the environment. For evaluating this, the robot will be given a target point (from its initial position) and will have to navigate to the target position whilst reacting according to your chosen behaviour in the presence of an obstacle. For this task, you might want to have a look at the move_base package and see if you can use it effectively. Other options are of course possible. \n",
    "     a. http://wiki.ros.org/move_base\n",
    "     b. https://husarion.com/tutorials/ros-tutorials/7-path-planning/\n",
    " \n",
    "\n",
    "2. Self-Localization and Mapping (30% of overall mark): Your robot will be required to navigate the environment collecting information and building a map. It needs to do so while avoiding obstacles. You can use either the  laser scan (preferred) or the RGBD to build the map (2D is required but you can attempt 3D if you want). For this you might want to use gmapping, or any other SLAM package that you deem suitable and explore_lite for the full mapping. \n",
    "     a. http://wiki.ros.org/navigation (Look at 6.3)\n",
    "     b. http://wiki.ros.org/gmapping\n",
    "     c. http://wiki.ros.org/slam_gmapping\n",
    "     d. http://wiki.ros.org/explore_lite\n",
    "     \n",
    "\n",
    "3. Object Detection (20% of overall mark): You will be required to integrate an existing object detection package and get it to work with your robot. The code is available online and can be found here: \n",
    "\n",
    "       a. http://wiki.ros.org/find_object_2d\n",
    "\n",
    "       b. https://husarion.com/core2/tutorials/ros-tutorials/4-visual-object-recognition/#4-visual-object-recognition-making-decision-with-recognized-object\n",
    "       \n",
    "\n",
    "4. Grand Challenge (30% of overall mark): You will use your robot to navigate and map the environment safely (task 1 & 2) and use 3 to detect individuals (alive or dead) as well as looking for risk signs. Once the robot is back from the compromised facilities, it should provide a report indicating the location of the signs and of the individuals on the constructed map, and whether the latter are still alive or dead. Ideally, this can be done in rviz using the marker facility. \n",
    "\n",
    "I strongly recommend that you use the ROS Navigation course in Ros Ignite to familiarize yourselves with the existing available packages and tools.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*Signs to detect: The signs to detect are shown below*\n",
    "<img src=./images/Picture2.png />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Marking:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Each group will produce and submit a report (on vision using link provided) of a maximum of 10 pages summarising their approach and results. IMPORTANT: PLEASE SUBMIT YOUR REPORT Direcly in the ROSJECT. This can be a word document or a pdf (preferred). **20% of the assignment mark**.\n",
    "\n",
    "2- Each group will submit their rosject using the following name: B31YS_Project_GroupNumber and send an email containing the shared link to y.r.petillot@hw.ac.uk. You will also download it as a zip file and submit it alongside your report in the vision link provided. IMPORTANT: PLEASE PROVIDE A README FILE and a LAUNCH FILE TO TEST YOUR DEMONSTRATION. DOWNLOAD THE ROSJECT AND SUBMIT IT AS A SINGLE ARCHIVE FILE ON VISION UNDER PROJECT ASSIGNMENT **50% of the assignment mark - marking scheme for this part is expained above**.\n",
    " \n",
    "3- Each group will demonstrate their work in simulation by providing a suitable launch file in their Rosject and an in class demonstration. We will also test this on real robots. A detailed schedule will be provided closer to the time. **30% of the assignment mark for simulation, 10% bonus points if you get it to work on the real robots**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#be2d24;\">How to launch the simulation</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This rosject contains all the initial environment and code to get started with your project. We have installed the code to run the simulation. To start the environment, just launch the following:\n",
    "\n",
    "roslaunch search_and_rescue search_and_rescue.launch\n",
    "\n",
    "Then launch rviz in a differrent terminal:\n",
    "\n",
    "rosrun rviz rviz\n",
    "\n",
    "You should see the robot in its environment in gazebo as well as the robot and the initial lidar data in rviz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#be2d24;\">How to provide the project</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have finished, \n",
    "save your rosject as **B31YS_Project_GroupNumber**\n",
    "* Then go to your rosjects list (top menu, world icon).\n",
    "* Then click on **Share** of your exam rosject\n",
    "* Copy the link that will appear there\n",
    "* Send an email to Prof. Yvan Petillot (y.r.petillot@hw.ac.uk) with the link in it.\n",
    "\n",
    "*IMPORTANT: PLEASE SUBMIT YOUR REPORT Direcly in the ROSJECT. This can be a word document or a pdf (preferred). PLEASE ALSO PROVIDE A LAUNCH FILE TO TEST YOUR DEMONSTRATION. FINALLY, DOWNLOAD THE ROSJECT AND SUBMIT IT AS A SINGLE ARCHIVE FILE ON VISION UNDER PROJECT ASSIGNMENT*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#be2d24;\">Done!!</span>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
